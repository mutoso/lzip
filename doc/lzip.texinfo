\input texinfo @c -*-texinfo-*-
@c %**start of header
@setfilename lzip.info
@settitle Lzip Manual
@finalout
@c %**end of header

@set UPDATED 30 April 2011
@set VERSION 1.12

@dircategory Data Compression
@direntry
* Lzip: (lzip).                 Data compressor based on the LZMA algorithm
@end direntry


@ifnothtml
@titlepage
@title Lzip
@subtitle Data compressor based on the LZMA algorithm
@subtitle for Lzip version @value{VERSION}, @value{UPDATED}
@author by Antonio Diaz Diaz

@page
@vskip 0pt plus 1filll
@end titlepage

@contents
@end ifnothtml

@node Top
@top

This manual is for Lzip (version @value{VERSION}, @value{UPDATED}).

@menu
* Introduction::          Purpose and features of lzip
* Algorithm::             How lzip compresses the data
* Invoking Lzip::         Command line interface
* File Format::           Detailed format of the compressed file
* Examples::              A small tutorial with examples
* Lziprecover::           Recovering data from damaged compressed files
* Invoking Lziprecover::  Command line interface
* Problems::              Reporting bugs
* Concept Index::         Index of concepts
@end menu

@sp 1
Copyright @copyright{} 2008, 2009, 2010, 2011 Antonio Diaz Diaz.

This manual is free documentation: you have unlimited permission
to copy, distribute and modify it.


@node Introduction
@chapter Introduction
@cindex introduction

Lzip is a lossless data compressor based on the LZMA algorithm, with
very safe integrity checking and a user interface similar to the one of
gzip or bzip2. Lzip decompresses almost as fast as gzip and compresses
better than bzip2, which makes it well suited for software distribution
and data archiving.

Lzip replaces every file given in the command line with a compressed
version of itself, with the name "original_name.lz". Each compressed
file has the same modification date, permissions, and, when possible,
ownership as the corresponding original, so that these properties can be
correctly restored at decompression time. Lzip is able to read from some
types of non regular files if the @samp{--stdout} option is specified.

If no file names are specified, lzip compresses (or decompresses) from
standard input to standard output. In this case, lzip will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

Lzip will correctly decompress a file which is the concatenation of two
or more compressed files. The result is the concatenation of the
corresponding uncompressed files. Integrity testing of concatenated
compressed files is also supported.

Lzip can produce multimember files and safely recover, with lziprecover,
the undamaged members in case of file damage. Lzip can also split the
compressed output in volumes of a given size, even when reading from
standard input. This allows the direct creation of multivolume
compressed tar archives.

The amount of memory required for compression is about 5 MiB plus 1 or 2
times the dictionary size limit (1 if input file size is less than
dictionary size limit, else 2) plus 8 times the dictionary size really
used. The option @samp{-0} is special and only requires about 1.5 MiB at
most. The amount of memory required for decompression is only a few tens
of KiB larger than the dictionary size really used.

Lzip will automatically use the smallest possible dictionary size
without exceeding the given limit. Keep in mind that the decompression
memory requirement is affected at compression time by the choice of
dictionary size limit.

When decompressing, lzip attempts to guess the name for the decompressed
file from that of the compressed file as follows:

@multitable {anyothername} {becomes} {anyothername.out}
@item filename.lz  @tab becomes @tab filename
@item filename.tlz @tab becomes @tab filename.tar
@item anyothername @tab becomes @tab anyothername.out
@end multitable

As a self-check for your protection, lzip stores in the member trailer
the 32-bit CRC of the original data and the size of the original data,
to make sure that the decompressed version of the data is identical to
the original. This guards against corruption of the compressed data, and
against undetected bugs in lzip (hopefully very unlikely). The chances
of data corruption going undetected are microscopic, less than one
chance in 4000 million for each member processed. Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong. It can't help you recover the original uncompressed
data.

Return values: 0 for a normal exit, 1 for environmental problems (file
not found, invalid flags, I/O errors, etc), 2 to indicate a corrupt or
invalid input file, 3 for an internal consistency error (eg, bug) which
caused lzip to panic.


@node Algorithm
@chapter Algorithm
@cindex algorithm

Lzip implements a simplified version of the LZMA (Lempel-Ziv-Markov
chain-Algorithm) algorithm. The high compression of LZMA comes from
combining two basic, well-proven compression ideas: sliding dictionaries
(LZ77/78) and markov models (the thing used by every compression
algorithm that uses a range encoder or similar order-0 entropy coder as
its last stage) with segregation of contexts according to what the bits
are used for.

Lzip is a two stage compressor. The first stage is a Lempel-Ziv coder,
which reduces redundancy by translating chunks of data to their
corresponding distance-length pairs. The second stage is a range encoder
that uses a different probability model for each type of data;
distances, lengths, literal bytes, etc.

The match finder, part of the LZ coder, is the most important piece of
the LZMA algorithm, as it is in many Lempel-Ziv based algorithms. Most
of lzip's execution time is spent in the match finder, and it has the
greatest influence on the compression ratio.

Here is how it works, step by step:

1) The member header is written to the output stream.

2) The first byte is coded literally, because there are no previous
bytes to which the match finder can refer to.

3) The main encoder advances to the next byte in the input data and
calls the match finder.

4) The match finder fills an array with the minimum distances before the
current byte where a match of a given length can be found.

5) Go back to step 3 until a sequence (formed of pairs, repeated
distances and literal bytes) of minimum price has been formed. Where the
price represents the number of output bits produced.

6) The range encoder encodes the sequence produced by the main encoder
and sends the produced bytes to the output stream.

7) Go back to step 3 until the input data is finished or until the
member or volume size limits are reached.

8) The range encoder is flushed.

9) The member trailer is written to the output stream.

10) If there are more data to compress, go back to step 1.

@sp 1
@noindent
The ideas embodied in lzip are due to (at least) the following people:
Abraham Lempel and Jacob Ziv (for the LZ algorithm), Andrey Markov (for
the definition of Markov chains), G.N.N. Martin (for the definition of
range encoding), Igor Pavlov (for putting all the above together in
LZMA), and Julian Seward (for bzip2's CLI and the idea of unzcrash).


@node Invoking Lzip
@chapter Invoking Lzip
@cindex invoking lzip
@cindex options
@cindex usage
@cindex version

The format for running lzip is:

@example
lzip [@var{options}] [@var{files}]
@end example

Lzip supports the following options:

@table @samp
@item -h
@itemx --help
Print an informative help message describing the options and exit.

@item -V
@itemx --version
Print the version number of lzip on the standard output and exit.

@item -b @var{size}
@itemx --member-size=@var{size}
Produce a multimember file and set the member size limit to @var{size}
bytes. Minimum member size limit is 100kB. Small member size may degrade
compression ratio, so use it only when needed. The default is to produce
single-member files.

@item -c
@itemx --stdout
Compress or decompress to standard output. Needed when reading from a
named pipe (fifo) or from a device. Use it to recover as much of the
uncompressed data as possible when decompressing a corrupt file.

@item -d
@itemx --decompress
Decompress.

@item -f
@itemx --force
Force overwrite of output file.

@item -F
@itemx --recompress
Force recompression of files whose name already has the @samp{.lz} or
@samp{.tlz} suffix.

@item -k
@itemx --keep
Keep (don't delete) input files during compression or decompression.

@item -m @var{length}
@itemx --match-length=@var{length}
Set the match length limit in bytes. After a match this long is found,
the search is finished. Valid values range from 5 to 273. Larger values
usually give better compression ratios but longer compression times.

@item -o @var{file}
@itemx --output=@var{file}
When reading from standard input and @samp{--stdout} has not been
specified, use @samp{@var{file}} as the virtual name of the uncompressed
file. This produces a file named @samp{@var{file}} when decompressing, a
file named @samp{@var{file}.lz} when compressing, and several files
named @samp{@var{file}00001.lz}, @samp{@var{file}00002.lz}, etc, when
compressing and splitting the output in volumes.

@item -q
@itemx --quiet
Quiet operation. Suppress all messages.

@item -s @var{size}
@itemx --dictionary-size=@var{size}
Set the dictionary size limit in bytes. Valid values range from 4KiB to
512MiB. Lzip will use the smallest possible dictionary size for each
member without exceeding this limit. Note that dictionary sizes are
quantized. If the specified size does not match one of the valid sizes,
it will be rounded upwards by adding up to (@var{size} / 16) to it.

For maximum compression you should use a dictionary size limit as large
as possible, but keep in mind that the decompression memory requirement
is affected at compression time by the choice of dictionary size limit.

@item -S @var{size}
@itemx --volume-size=@var{size}
Split the compressed output into several volume files with names
@samp{original_name00001.lz}, @samp{original_name00002.lz}, etc, and set
the volume size limit to @var{size} bytes. Each volume is a complete,
maybe multimember, lzip file. Minimum volume size limit is 100kB. Small
volume size may degrade compression ratio, so use it only when needed.

@item -t
@itemx --test
Check integrity of the specified file(s), but don't decompress them.
This really performs a trial decompression and throws away the result.
Use it together with @samp{-v} to see information about the file.

@item -v
@itemx --verbose
Verbose mode.
When compressing, show the compression ratio for each file processed.
When decompressing or testing, further -v's (up to 4) increase the
verbosity level, showing status, dictionary size, compression ratio,
trailer contents (CRC, data size, member size), and up to 6 bytes of
trailing garbage (if any).

@item -0 .. -9
Set the compression parameters (dictionary size and match length limit)
as shown in the table below. Note that @samp{-9} can be much slower than
@samp{-0}. These options have no effect when decompressing.

The bidimensional parameter space of LZMA can't be mapped to a linear
scale optimal for all files. If your files are large, very repetitive,
etc, you may need to use the @samp{--match-length} and
@samp{--dictionary-size} options directly to achieve optimal
performance.

@multitable {Level} {Dictionary size} {Match length limit}
@item Level @tab Dictionary size @tab Match length limit
@item -0 @tab 64 KiB @tab  16 bytes
@item -1 @tab  1 MiB @tab   5 bytes
@item -2 @tab  1.5 MiB @tab   6 bytes
@item -3 @tab  2 MiB @tab   8 bytes
@item -4 @tab  3 MiB @tab  12 bytes
@item -5 @tab  4 MiB @tab  20 bytes
@item -6 @tab  8 MiB @tab  36 bytes
@item -7 @tab 16 MiB @tab  68 bytes
@item -8 @tab 24 MiB @tab 132 bytes
@item -9 @tab 32 MiB @tab 273 bytes
@end multitable

@item --fast
@itemx --best
Aliases for GNU gzip compatibility.

@end table

@sp 1
Numbers given as arguments to options may be followed by a multiplier
and an optional @samp{B} for "byte".

Table of SI and binary prefixes (unit multipliers):

@multitable {Prefix} {kilobyte  (10^3 = 1000)} {|} {Prefix} {kibibyte (2^10 = 1024)}
@item Prefix @tab Value               @tab | @tab Prefix @tab Value
@item k @tab kilobyte  (10^3 = 1000)  @tab | @tab Ki @tab kibibyte (2^10 = 1024)
@item M @tab megabyte  (10^6)         @tab | @tab Mi @tab mebibyte (2^20)
@item G @tab gigabyte  (10^9)         @tab | @tab Gi @tab gibibyte (2^30)
@item T @tab terabyte  (10^12)        @tab | @tab Ti @tab tebibyte (2^40)
@item P @tab petabyte  (10^15)        @tab | @tab Pi @tab pebibyte (2^50)
@item E @tab exabyte   (10^18)        @tab | @tab Ei @tab exbibyte (2^60)
@item Z @tab zettabyte (10^21)        @tab | @tab Zi @tab zebibyte (2^70)
@item Y @tab yottabyte (10^24)        @tab | @tab Yi @tab yobibyte (2^80)
@end multitable


@node File Format
@chapter File Format
@cindex file format

In the diagram below, a box like this:
@verbatim
+---+
|   | <-- the vertical bars might be missing
+---+
@end verbatim

represents one byte; a box like this:
@verbatim
+==============+
|              |
+==============+
@end verbatim

represents a variable number of bytes.

@sp 1
A lzip file consists of a series of "members" (compressed data sets).
The members simply appear one after another in the file, with no
additional information before, between, or after them.

Each member has the following structure:
@verbatim
+--+--+--+--+----+----+=============+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
| ID string | VN | DS | Lzma stream | CRC32 |   Data size   |  Member size  |
+--+--+--+--+----+----+=============+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
@end verbatim

All multibyte values are stored in little endian order.

@table @samp
@item ID string
A four byte string, identifying the lzip format, with the value "LZIP".

@item VN (version number, 1 byte)
Just in case something needs to be modified in the future. Valid values
are 0 and 1. Version 0 files are deprecated. They can contain only one
member and lack the @samp{Member size} field.

@item DS (coded dictionary size, 1 byte)
Bits 4-0 contain the base 2 logarithm of the base dictionary size.@*
Bits 7-5 contain the number of "wedges" to substract from the base
dictionary size to obtain the dictionary size. The size of a wedge is
(base dictionary size / 16).@*
Valid values for dictionary size range from 4KiB to 512MiB.

@item Lzma stream
The lzma stream, finished by an end of stream marker. Uses default values
for encoder properties.

@item CRC32 (4 bytes)
CRC of the uncompressed original data.

@item Data size (8 bytes)
Size of the uncompressed original data.

@item Member size (8 bytes)
Total size of the member, including header and trailer. This facilitates
safe recovery of undamaged members from multimember files.

@end table


@node Examples
@chapter A small tutorial with examples
@cindex examples

WARNING! Even if lzip is bug-free, other causes may result in a corrupt
compressed file (bugs in the system libraries, memory errors, etc).
Therefore, if the data you are going to compress is important give the
@samp{--keep} option to lzip and do not remove the original file until
you verify the compressed file with a command like @w{@samp{lzip -cd
file.lz | cmp file -}}.

@sp 1
@noindent
Example 1: Replace a regular file with its compressed version file.lz
and show the compression ratio.

@example
lzip -v file
@end example

@sp 1
@noindent
Example 2: Like example 1 but the created file.lz is multimember with a
member size of 1MiB. The compression ratio is not shown.

@example
lzip -b 1MiB file
@end example

@sp 1
@noindent
Example 3: Restore a regular file from its compressed version file.lz.
If the operation is successful, file.lz is removed.

@example
lzip -d file.lz
@end example

@sp 1
@noindent
Example 4: Verify the integrity of the compressed file file.lz and show
status.

@example
lzip -tv file.lz
@end example

@sp 1
@noindent
Example 5: Compress a whole floppy in /dev/fd0 and send the output to
file.lz.

@example
lzip -c /dev/fd0 > file.lz
@end example

@sp 1
@noindent
Example 6: Decompress file.lz partially until 10KiB of decompressed data
are produced.

@example
lzip -cd file.lz | dd bs=1024 count=10
@end example

@sp 1
@noindent
Example 7: Create a multivolume compressed tar archive with a volume
size of 1440KiB.

@example
tar -c some_directory | lzip -S 1440KiB -o volume_name
@end example

@sp 1
@noindent
Example 8: Extract a multivolume compressed tar archive.

@example
lzip -cd volume_name*.lz | tar -xf -
@end example

@sp 1
@noindent
Example 9: Create a multivolume compressed backup of a big database file
with a volume size of 650MB, where each volume is a multimember file
with a member size of 32MiB.

@example
lzip -b 32MiB -S 650MB big_db
@end example

@sp 1
@anchor{ddrescue-example}
@noindent
Example 10: Recover a compressed backup from two copies on CD-ROM (see
the GNU ddrescue manual for details about ddrescue)

@example
ddrescue -b2048 /dev/cdrom cdimage1 logfile1
mount -t iso9660 -o loop,ro cdimage1 /mnt/cdimage
cp /mnt/cdimage/backup.tar.lz rescued1.tar.lz
umount /mnt/cdimage
  (insert second copy in the CD drive)
ddrescue -b2048 /dev/cdrom cdimage2 logfile2
mount -t iso9660 -o loop,ro cdimage2 /mnt/cdimage
cp /mnt/cdimage/backup.tar.lz rescued2.tar.lz
umount /mnt/cdimage
lziprecover -m -v -o rescued.tar.lz rescued1.tar.lz rescued2.tar.lz
@end example

@sp 1
@noindent
Example 11: Recover the first volume of those created in example 9 from
two copies, @samp{big_db1_00001.lz} and @samp{big_db2_00001.lz}, with
member 00007 damaged in the first copy, member 00018 damaged in the
second copy, and member 00012 damaged in both copies. (Indented lines
are abridged error messages from lzip/lziprecover). Two correct copies
are produced and compared.

@example
lziprecover -s big_db1_00001.lz
lziprecover -s big_db2_00001.lz
lzip -t rec*big_db1_00001.lz
  rec00007big_db1_00001.lz: crc mismatch
  rec00012big_db1_00001.lz: crc mismatch
lzip -t rec*big_db2_00001.lz
  rec00012big_db2_00001.lz: crc mismatch
  rec00018big_db2_00001.lz: crc mismatch
lziprecover -m -v rec00012big_db1_00001.lz rec00012big_db2_00001.lz
  Input files merged successfully
cp rec00007big_db2_00001.lz rec00007big_db1_00001.lz
cp rec00012big_db1_00001_fixed.lz rec00012big_db1_00001.lz
cp rec00012big_db1_00001_fixed.lz rec00012big_db2_00001.lz
cp rec00018big_db1_00001.lz rec00018big_db2_00001.lz
cat rec*big_db1_00001.lz > big_db3_00001.lz
cat rec*big_db2_00001.lz > big_db4_00001.lz
zcmp big_db3_00001.lz big_db4_00001.lz
@end example


@node Lziprecover
@chapter Lziprecover
@cindex lziprecover

Lziprecover is a data recovery tool for lzip compressed files able to
repair slightly damaged files, recover badly damaged files from two or
more copies, and extract undamaged members from multi-member files.

Lziprecover takes as arguments the names of the damaged files and writes
zero or more recovered files depending on the operation selected and
whether the recovery succeeded or not. The damaged files themselves are
never modified.

If the files are too damaged for lziprecover to repair them, data from
damaged members can be partially recovered writing it to stdout as shown
in the following example (the resulting file may contain garbage data at
the end):

@example
lzip -cd rec00001file.lz > rec00001file
@end example

If the cause of file corruption is damaged media, the combination GNU
ddrescue + lziprecover is the best option for recovering data from
multiple damaged copies. @xref{ddrescue-example}, for an example.


@node Invoking Lziprecover
@chapter Invoking Lziprecover
@cindex invoking lziprecover

The format for running lziprecover is:

@example
lziprecover [@var{options}] [@var{files}]
@end example

Lziprecover supports the following options:

@table @samp
@item -h
@itemx --help
Print an informative help message describing the options and exit.

@item -V
@itemx --version
Print the version number of lziprecover on the standard output and exit.

@item -f
@itemx --force
Force overwrite of output file.

@item -m
@itemx --merge
Try to produce a correct file merging the good parts of two or more
damaged copies. The copies must be single-member files. The merge will
fail if the copies have too many damaged areas or if the same byte is
damaged in all copies. If successful, a repaired copy is written to the
file @samp{@var{file}_fixed.lz}.

To give you an idea of its possibilities, when merging two copies each
of them with one damaged area affecting 1 percent of the copy, the
probability of obtaining a correct file is about 98 percent. With three
such copies the probability rises to 99.97 percent. For large files with
small errors, the probability approaches 100 percent even with only two
copies.

@item -o @var{file}
@itemx --output=@var{file}
Place the output into @samp{@var{file}} instead of into
@samp{@var{file}_fixed.lz}.

If splitting, the names of the files produced are in the form
@samp{rec00001@var{file}}, etc.

@item -q
@itemx --quiet
Quiet operation. Suppress all messages.

@item -R
@itemx --repair
Try to repair a small error, affecting only one byte, in a single-member
@var{file}. If successful, a repaired copy is written to the file
@samp{@var{file}_fixed.lz}. @samp{@var{file}} is not modified at all.

@item -s
@itemx --split
Search for members in @samp{@var{file}} and write each member in its own
@samp{.lz} file. You can then use @samp{lzip -t} to test the integrity
of the resulting files, decompress those which are undamaged, and try to
repair or partially decompress those which are damaged.

The names of the files produced are in the form
@samp{rec00001@var{file}.lz}, @samp{rec00002@var{file}.lz}, etc, and are
designed so that the use of wildcards in subsequent processing, for
example, @w{@samp{lzip -cd rec*@var{file}.lz > recovered_data}},
processes the files in the correct order.

@item -v
@itemx --verbose
Verbose mode. Further -v's increase the verbosity level.

@end table


@node Problems
@chapter Reporting Bugs
@cindex bugs
@cindex getting help

There are probably bugs in lzip. There are certainly errors and
omissions in this manual. If you report them, they will get fixed. If
you don't, no one will ever know about them and they will remain unfixed
for all eternity, if not longer.

If you find a bug in lzip, please send electronic mail to
@email{lzip-bug@@nongnu.org}. Include the version number, which you can
find by running @w{@samp{lzip --version}}.


@node Concept Index
@unnumbered Concept Index

@printindex cp

@bye

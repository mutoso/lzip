Description

Lzip is a lossless file compressor based on the LZMA (Lempel-Ziv-Markov
chain-Algorithm) algorithm. The high compression of LZMA comes from
combining two basic, well-proven compression ideas: sliding dictionaries
(i.e. LZ77/78), and markov models (i.e. the thing used by every
compression algorithm that uses a range encoder or similar order-0
entropy coder as its last stage) with segregation of contexts according
to what the bits are used for.

Lzip is not a replacement for gzip or bzip2, but a complement; which one
is best to use depends on user's needs. Gzip is the fastest and most
widely used. Bzip2 compresses better than gzip but is slower, both
compressing and decompressing. Lzip decompresses almost as fast as gzip
and compresses better than bzip2, but requires more memory and time
during compression.

The amount of memory required for compression is about 6 times the
dictionary size, for decompression is a little more than dictionary
size. It is also important to appreciate that the decompression memory
requirement is set at compression time by the choice of dictionary size.

Lzip has a similar interface to gzip and bzip2. It replaces every file
given in the command line with a compressed version of itself, with the
name "original_name.lz". Each compressed file has the same modification
date, permissions, and, when possible, ownership as the corresponding
original, so that these properties can be correctly restored at
decompression time.

If no file names are specified, Lzip compresses (or decompresses) from
standard input to standard output. In this case, Lzip will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

Lzip will correctly decompress a file which is the concatenation of two
or more compressed files. The result is the concatenation of the
corresponding uncompressed files. Integrity testing of concatenated
compressed files is also supported.

As a self-check for your protection, Lzip stores in the file trailer the
32-bit CRC of the original file and the size of the original file, to
make sure that the decompressed version of the file is identical to the
original. This guards against corruption of the compressed data, and
against undetected bugs in Lzip (hopefully very unlikely). The chances
of data corruption going undetected are microscopic, less than one
chance in 4000 million for each file processed. Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong. It can't help you recover the original uncompressed
data.


Copyright (C) 2008 Antonio Diaz Diaz.

This file is free documentation: you have unlimited permission to copy,
distribute and modify it.

The file Makefile.in is a data file used by configure to produce the
Makefile. It has the same copyright owner and permissions that this
file.
